// clang-format off
// DO NOT EDIT;
// Generated by ml/nn/runtime/test/specs/generate_vts_test.sh
// Generated from: argmax_1_float.mod.py.
namespace argmax_1_float {
// Generated argmax_1_float test
#include "examples/argmax_1_float.example.cpp"
// Generated model constructor
#include "vts_models/argmax_1_float.model.cpp"
} // namespace argmax_1_float

TEST_F(NeuralnetworksHidlTest, argmax_1_float) {
  generated_tests::Execute(device,
                           argmax_1_float::createTestModel,
                           argmax_1_float::is_ignored,
                           argmax_1_float::examples);
}

// Generated from: argmax_1_float_relaxed.mod.py.
namespace argmax_1_float_relaxed {
// Generated argmax_1_float_relaxed test
#include "examples/argmax_1_float_relaxed.example.cpp"
// Generated model constructor
#include "vts_models/argmax_1_float_relaxed.model.cpp"
} // namespace argmax_1_float_relaxed

TEST_F(NeuralnetworksHidlTest, argmax_1_float_relaxed) {
  generated_tests::Execute(device,
                           argmax_1_float_relaxed::createTestModel,
                           argmax_1_float_relaxed::is_ignored,
                           argmax_1_float_relaxed::examples);
}

// Generated from: argmax_1_int32.mod.py.
namespace argmax_1_int32 {
// Generated argmax_1_int32 test
#include "examples/argmax_1_int32.example.cpp"
// Generated model constructor
#include "vts_models/argmax_1_int32.model.cpp"
} // namespace argmax_1_int32

TEST_F(NeuralnetworksHidlTest, argmax_1_int32) {
  generated_tests::Execute(device,
                           argmax_1_int32::createTestModel,
                           argmax_1_int32::is_ignored,
                           argmax_1_int32::examples);
}

// Generated from: argmax_1_quant8.mod.py.
namespace argmax_1_quant8 {
// Generated argmax_1_quant8 test
#include "examples/argmax_1_quant8.example.cpp"
// Generated model constructor
#include "vts_models/argmax_1_quant8.model.cpp"
} // namespace argmax_1_quant8

TEST_F(NeuralnetworksHidlTest, argmax_1_quant8) {
  generated_tests::Execute(device,
                           argmax_1_quant8::createTestModel,
                           argmax_1_quant8::is_ignored,
                           argmax_1_quant8::examples);
}

// Generated from: argmax_2_float.mod.py.
namespace argmax_2_float {
// Generated argmax_2_float test
#include "examples/argmax_2_float.example.cpp"
// Generated model constructor
#include "vts_models/argmax_2_float.model.cpp"
} // namespace argmax_2_float

TEST_F(NeuralnetworksHidlTest, argmax_2_float) {
  generated_tests::Execute(device,
                           argmax_2_float::createTestModel,
                           argmax_2_float::is_ignored,
                           argmax_2_float::examples);
}

// Generated from: argmax_2_float_relaxed.mod.py.
namespace argmax_2_float_relaxed {
// Generated argmax_2_float_relaxed test
#include "examples/argmax_2_float_relaxed.example.cpp"
// Generated model constructor
#include "vts_models/argmax_2_float_relaxed.model.cpp"
} // namespace argmax_2_float_relaxed

TEST_F(NeuralnetworksHidlTest, argmax_2_float_relaxed) {
  generated_tests::Execute(device,
                           argmax_2_float_relaxed::createTestModel,
                           argmax_2_float_relaxed::is_ignored,
                           argmax_2_float_relaxed::examples);
}

// Generated from: argmax_2_int32.mod.py.
namespace argmax_2_int32 {
// Generated argmax_2_int32 test
#include "examples/argmax_2_int32.example.cpp"
// Generated model constructor
#include "vts_models/argmax_2_int32.model.cpp"
} // namespace argmax_2_int32

TEST_F(NeuralnetworksHidlTest, argmax_2_int32) {
  generated_tests::Execute(device,
                           argmax_2_int32::createTestModel,
                           argmax_2_int32::is_ignored,
                           argmax_2_int32::examples);
}

// Generated from: argmax_2_quant8.mod.py.
namespace argmax_2_quant8 {
// Generated argmax_2_quant8 test
#include "examples/argmax_2_quant8.example.cpp"
// Generated model constructor
#include "vts_models/argmax_2_quant8.model.cpp"
} // namespace argmax_2_quant8

TEST_F(NeuralnetworksHidlTest, argmax_2_quant8) {
  generated_tests::Execute(device,
                           argmax_2_quant8::createTestModel,
                           argmax_2_quant8::is_ignored,
                           argmax_2_quant8::examples);
}

// Generated from: argmin_1_float.mod.py.
namespace argmin_1_float {
// Generated argmin_1_float test
#include "examples/argmin_1_float.example.cpp"
// Generated model constructor
#include "vts_models/argmin_1_float.model.cpp"
} // namespace argmin_1_float

TEST_F(NeuralnetworksHidlTest, argmin_1_float) {
  generated_tests::Execute(device,
                           argmin_1_float::createTestModel,
                           argmin_1_float::is_ignored,
                           argmin_1_float::examples);
}

// Generated from: argmin_1_float_relaxed.mod.py.
namespace argmin_1_float_relaxed {
// Generated argmin_1_float_relaxed test
#include "examples/argmin_1_float_relaxed.example.cpp"
// Generated model constructor
#include "vts_models/argmin_1_float_relaxed.model.cpp"
} // namespace argmin_1_float_relaxed

TEST_F(NeuralnetworksHidlTest, argmin_1_float_relaxed) {
  generated_tests::Execute(device,
                           argmin_1_float_relaxed::createTestModel,
                           argmin_1_float_relaxed::is_ignored,
                           argmin_1_float_relaxed::examples);
}

// Generated from: argmin_1_int32.mod.py.
namespace argmin_1_int32 {
// Generated argmin_1_int32 test
#include "examples/argmin_1_int32.example.cpp"
// Generated model constructor
#include "vts_models/argmin_1_int32.model.cpp"
} // namespace argmin_1_int32

TEST_F(NeuralnetworksHidlTest, argmin_1_int32) {
  generated_tests::Execute(device,
                           argmin_1_int32::createTestModel,
                           argmin_1_int32::is_ignored,
                           argmin_1_int32::examples);
}

// Generated from: argmin_1_quant8.mod.py.
namespace argmin_1_quant8 {
// Generated argmin_1_quant8 test
#include "examples/argmin_1_quant8.example.cpp"
// Generated model constructor
#include "vts_models/argmin_1_quant8.model.cpp"
} // namespace argmin_1_quant8

TEST_F(NeuralnetworksHidlTest, argmin_1_quant8) {
  generated_tests::Execute(device,
                           argmin_1_quant8::createTestModel,
                           argmin_1_quant8::is_ignored,
                           argmin_1_quant8::examples);
}

// Generated from: argmin_2_float.mod.py.
namespace argmin_2_float {
// Generated argmin_2_float test
#include "examples/argmin_2_float.example.cpp"
// Generated model constructor
#include "vts_models/argmin_2_float.model.cpp"
} // namespace argmin_2_float

TEST_F(NeuralnetworksHidlTest, argmin_2_float) {
  generated_tests::Execute(device,
                           argmin_2_float::createTestModel,
                           argmin_2_float::is_ignored,
                           argmin_2_float::examples);
}

// Generated from: argmin_2_float_relaxed.mod.py.
namespace argmin_2_float_relaxed {
// Generated argmin_2_float_relaxed test
#include "examples/argmin_2_float_relaxed.example.cpp"
// Generated model constructor
#include "vts_models/argmin_2_float_relaxed.model.cpp"
} // namespace argmin_2_float_relaxed

TEST_F(NeuralnetworksHidlTest, argmin_2_float_relaxed) {
  generated_tests::Execute(device,
                           argmin_2_float_relaxed::createTestModel,
                           argmin_2_float_relaxed::is_ignored,
                           argmin_2_float_relaxed::examples);
}

// Generated from: argmin_2_int32.mod.py.
namespace argmin_2_int32 {
// Generated argmin_2_int32 test
#include "examples/argmin_2_int32.example.cpp"
// Generated model constructor
#include "vts_models/argmin_2_int32.model.cpp"
} // namespace argmin_2_int32

TEST_F(NeuralnetworksHidlTest, argmin_2_int32) {
  generated_tests::Execute(device,
                           argmin_2_int32::createTestModel,
                           argmin_2_int32::is_ignored,
                           argmin_2_int32::examples);
}

// Generated from: argmin_2_quant8.mod.py.
namespace argmin_2_quant8 {
// Generated argmin_2_quant8 test
#include "examples/argmin_2_quant8.example.cpp"
// Generated model constructor
#include "vts_models/argmin_2_quant8.model.cpp"
} // namespace argmin_2_quant8

TEST_F(NeuralnetworksHidlTest, argmin_2_quant8) {
  generated_tests::Execute(device,
                           argmin_2_quant8::createTestModel,
                           argmin_2_quant8::is_ignored,
                           argmin_2_quant8::examples);
}

// Generated from: lsh_projection_3_relaxed.mod.py.
namespace lsh_projection_3_relaxed {
// Generated lsh_projection_3_relaxed test
#include "examples/lsh_projection_3_relaxed.example.cpp"
// Generated model constructor
#include "vts_models/lsh_projection_3_relaxed.model.cpp"
} // namespace lsh_projection_3_relaxed

TEST_F(NeuralnetworksHidlTest, lsh_projection_3_relaxed) {
  generated_tests::Execute(device,
                           lsh_projection_3_relaxed::createTestModel,
                           lsh_projection_3_relaxed::is_ignored,
                           lsh_projection_3_relaxed::examples);
}

// Generated from: lsh_projection_4_relaxed.mod.py.
namespace lsh_projection_4_relaxed {
// Generated lsh_projection_4_relaxed test
#include "examples/lsh_projection_4_relaxed.example.cpp"
// Generated model constructor
#include "vts_models/lsh_projection_4_relaxed.model.cpp"
} // namespace lsh_projection_4_relaxed

TEST_F(NeuralnetworksHidlTest, lsh_projection_4_relaxed) {
  generated_tests::Execute(device,
                           lsh_projection_4_relaxed::createTestModel,
                           lsh_projection_4_relaxed::is_ignored,
                           lsh_projection_4_relaxed::examples);
}

// Generated from: lsh_projection_deprecated.mod.py.
namespace lsh_projection_deprecated {
// Generated lsh_projection_deprecated test
#include "examples/lsh_projection_deprecated.example.cpp"
// Generated model constructor
#include "vts_models/lsh_projection_deprecated.model.cpp"
} // namespace lsh_projection_deprecated

TEST_F(NeuralnetworksHidlTest, lsh_projection_deprecated) {
  generated_tests::Execute(device,
                           lsh_projection_deprecated::createTestModel,
                           lsh_projection_deprecated::is_ignored,
                           lsh_projection_deprecated::examples);
}

// Generated from: pad_v2_1_float.mod.py.
namespace pad_v2_1_float {
// Generated pad_v2_1_float test
#include "examples/pad_v2_1_float.example.cpp"
// Generated model constructor
#include "vts_models/pad_v2_1_float.model.cpp"
} // namespace pad_v2_1_float

TEST_F(NeuralnetworksHidlTest, pad_v2_1_float) {
  generated_tests::Execute(device,
                           pad_v2_1_float::createTestModel,
                           pad_v2_1_float::is_ignored,
                           pad_v2_1_float::examples);
}

// Generated from: pad_v2_1_float_relaxed.mod.py.
namespace pad_v2_1_float_relaxed {
// Generated pad_v2_1_float_relaxed test
#include "examples/pad_v2_1_float_relaxed.example.cpp"
// Generated model constructor
#include "vts_models/pad_v2_1_float_relaxed.model.cpp"
} // namespace pad_v2_1_float_relaxed

TEST_F(NeuralnetworksHidlTest, pad_v2_1_float_relaxed) {
  generated_tests::Execute(device,
                           pad_v2_1_float_relaxed::createTestModel,
                           pad_v2_1_float_relaxed::is_ignored,
                           pad_v2_1_float_relaxed::examples);
}

// Generated from: pad_v2_1_quant8.mod.py.
namespace pad_v2_1_quant8 {
// Generated pad_v2_1_quant8 test
#include "examples/pad_v2_1_quant8.example.cpp"
// Generated model constructor
#include "vts_models/pad_v2_1_quant8.model.cpp"
} // namespace pad_v2_1_quant8

TEST_F(NeuralnetworksHidlTest, pad_v2_1_quant8) {
  generated_tests::Execute(device,
                           pad_v2_1_quant8::createTestModel,
                           pad_v2_1_quant8::is_ignored,
                           pad_v2_1_quant8::examples);
}

